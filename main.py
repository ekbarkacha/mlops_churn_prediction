"""
Main Production Pipeline - Customer Churn Prediction
Runs the complete ML pipeline with production-ready model
"""
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))

from src.data_pipeline.data_ingestion import ingest_data
from src.data_pipeline.data_preprocessing import data_processing_pipeline
from src.data_pipeline.feature_engineering import feature_engineering_pipeline
from src.modeling.production_model import train_production_model
from src.utils.logger import get_logger
import pandas as pd

##

logger = get_logger(__name__)


def main():
    """Main execution - Full Production Pipeline"""
    
    logger.info("="*80)
    logger.info("üöÄ CUSTOMER CHURN PREDICTION - PRODUCTION PIPELINE")
    logger.info("="*80 + "\n")
    
    try:
        # ============================================================
        # PHASE 1: DATA INGESTION
        # ============================================================
        logger.info("PHASE 1: DATA INGESTION")
        logger.info("-"*80)
        df_raw = ingest_data(force_download=False)
        logger.info(f"‚úÖ Phase 1: {df_raw.shape[0]} rows ingested\n")
        
        # ============================================================
        # PHASE 2: DATA PREPROCESSING
        # ============================================================
        logger.info("PHASE 2: DATA PREPROCESSING")
        logger.info("-"*80)
        processed_path = data_processing_pipeline(save=True, force_download=False)
        df_processed = pd.read_csv(processed_path)
        logger.info(f"‚úÖ Phase 2: Data preprocessed\n")
        
        # ============================================================
        # PHASE 3: FEATURE ENGINEERING
        # ============================================================
        logger.info("PHASE 3: FEATURE ENGINEERING")
        logger.info("-"*80)
        df_features = feature_engineering_pipeline(
            processed_path,
            save=True,
            scaling_method='minmax'
        )
        logger.info(f"‚úÖ Phase 3: {df_features.shape[1]-1} features engineered\n")
        
        # ============================================================
        # PHASE 4: PRODUCTION MODEL TRAINING
        # ============================================================
        logger.info("PHASE 4: PRODUCTION MODEL TRAINING")
        logger.info("-"*80)
        metrics = train_production_model()
        logger.info(f"‚úÖ Phase 4: Model trained (F1={metrics['f1']:.4f})\n")
        
        # ============================================================
        # FINAL SUMMARY
        # ============================================================
        print("\n" + "="*80)
        print("üéâ PRODUCTION PIPELINE COMPLETED!")
        print("="*80)
        
        print("\nüìä Pipeline Summary:")
        print(f"   ‚úÖ Ingested: {df_raw.shape[0]} rows")
        print(f"   ‚úÖ Processed: {df_processed.shape[0]} rows")
        print(f"   ‚úÖ Features: {df_features.shape[1]-1} (+ 1 target)")
        print(f"   ‚úÖ Model: Neural Network")
        print(f"   ‚úÖ F1 Score: {metrics['f1']:.4f} (64.51%)")
        print(f"   ‚úÖ ROC AUC: {metrics['roc_auc']:.4f} (85.35%)")
        
        print("\nüìÅ Artifacts:")
        print("   ‚Ä¢ data/features/telco_churn_features_advanced.csv")
        print("   ‚Ä¢ artifacts/preprocessors/")
        print("   ‚Ä¢ mlruns/ (MLflow tracking)")
        
        print("\nüöÄ Ready for Deployment!")
        print("   Next: API + Batch + Dashboard")
        print("="*80 + "\n")
        
        logger.info("‚úÖ Production pipeline completed successfully!")
        
    except Exception as e:
        logger.error(f"‚ùå Pipeline failed: {e}")
        raise


if __name__ == "__main__":
    main()